[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Un Enfoque Bayesiano",
    "section": "",
    "text": "Un Enfoque Bayesiano\nPor Miguel Ángel Castañeda Martínez."
  },
  {
    "objectID": "index.html#introducción",
    "href": "index.html#introducción",
    "title": "Un Enfoque Bayesiano",
    "section": "Introducción",
    "text": "Introducción\n\nCuando empecé mi trayectoria como científico de datos tenía escaso conocimiento de lenguajes de programación, modelos de aprendizaje de máquina, análisis exploratorio de datos, etc. En un inicio imaginaba que la analítica de datos iba más por el camino de los sistemas, el poder computacional, y los algoritmos, pero nunca imaginé que tuviera algo que ver con estadística. Para mí la estadística era una materia más con la que se tenía que cumplir en la carrera, la veía como algo arcaico incluso tedioso. Poco imaginaba que años después terminaría siendo de mis temas favoritos, que encontraría fascinante el inmenso mundo del que se trata, y que me daría cuenta del enorme abanico de aplicaciones que tiene.\nEn este breve ensayo intento mostrar, con un ejemplo aplicado, las diferencias entre un enfoque frecuentista y un enfoque bayesiano. Cabe destacar que es la opinión de una persona que empieza a adentrarse en el mundo de la estadística bayesiana, que considera que la mejor manera de asimilar el conocimiento es compartiéndolo, y que por tanto está haciendo un esfuerzo por transmitir sus primeras impresiones e intuiciones del tema.\nEl ejemplo que utilizaré para mostrar los conceptos es con datos de encuestas realizadas para la elección presidencial del 2008 en Estados Unidos, mismos que se pueden encontrar en el portal de Pew Research Center. Este ejemplo fue extraido del libro Bayesian Data Analysis, Andrew Gelman, 3° edición - p. 61, y es una expansión de un trabajo realizado para la materia de Fundamentos de estadística impartida en la Maestría en Ciencia de Datos del ITAM , por quien rápidamente se posicionaría como una de las mejores profesoras que he tenido en mi trayectoria profesional, Teresa Ortiz"
  },
  {
    "objectID": "index.html#el-problema",
    "href": "index.html#el-problema",
    "title": "Un Enfoque Bayesiano",
    "section": "El problema",
    "text": "El problema\n\nComo es bien sabido, la elección de Estados Unidos en el 2008 la ganó el candidato presidencial por el partido demócrata, Barack Obama. Se podría pensar que existe cierta correlación entre la proporción de votos que recibió Obama, con la proporción de votantes que se identifican liberales en cada estado, por lo que para ilustrar ambos enfoques, se realizará una comparación entre la proporción de la población de cada estado que tiene ideología política “muy liberal” (en lo subsecuente very liberal), contra el porcentaje de votos que recibió el candidato en cada estado.\nPara hacer dicha comparación se tienen dos conjuntos de datos, el primero de ellos es el de las encuestas realizadas a la ciudadanía del país, para el cual cada registro es una persona encuestada, y son de interés las siguientes variables:\n\nstate: Estado en el que se realizó la encuesta.\nsurvey: Identificador de la encuesta aplicada en cada registro.\nideo: Ideología política del encuestado.\n\nEl segundo de ellos contiene los resultados de la elección por estado, para el cual el foco de atención estará en las variables a continuación:\n\nstate: Estado de referencia.\nvote_Obama_pct: Porcentaje de votos por Obama."
  },
  {
    "objectID": "index.html#enfoque-frecuentista",
    "href": "index.html#enfoque-frecuentista",
    "title": "Un Enfoque Bayesiano",
    "section": "Enfoque Frecuentista",
    "text": "Enfoque Frecuentista\n\nPara la primera parte del análisis se obtendrá la proporción de la población que se identifica very liberal utilizando un enfoque frecuentista, es decir, se puede obtener la proporción de máxima verosimilitud utilizando una distribución binomial. Para ello, se puede ver a cada uno de los \\(n\\) encuestados de un estado en particular \\(X = \\{x_1,x_2,...,x_n\\}\\), como \\(n\\) muestras de una variable aleatoria independiente e idénticamente distribuida, y que siguen una distribución \\(x_i \\backsim B(k=1, p=\\theta)\\), en donde una persona con dicha ideología es considerada como un éxito bajo una binomial.\nEl estimador de máxima verosimilitud para una distribución binomial bajo \\(k=1\\) está dada por:\n\\[\\theta = \\bar x\\]\nEn el caso del ejemplo, se puede obtener dicho estimador de proporción (prop_mle) utilizando el total de las encuestas realizadas en un estado (survey_total), y el total de encuestados que se identificaron very liberal (survey_very_lib) en su ideología política. Esto se observa con mayor detalle en la siguiente tabla, misma que por simplicidad solamente muestra los primeros cinco estados.\n\n\n\n\n\n\nNote\n\n\n\nLa demostración del estimador \\(\\theta\\) se puede encontrar en el Anexo 1.\n\n\n\n\n\nCode\n#Carga de datos de encuestas\npoll_data = pd.read_stata('./data/pew_research_center_june_elect_wknd_data.dta')\n\n#Paso 1: Se agrupa por estado para obtener el número de encuestas realizadas en cada estada\nstate = poll_data.groupby(by='state').count()\nstate.reset_index(inplace=True)\nstate = state[['state', 'survey']]\n\n#Paso 2: Se agrupa por estado e ideología para filtrar encuestas very liberal\nideo = poll_data.groupby(by=['state','ideo']).count()\nideo.reset_index(inplace=True)\nideo = ideo[['state', 'ideo', 'survey']]\nvery_liberal = ideo.loc[ideo['ideo'] == 'very liberal']\n\n#Paso 3: Se unen los dos conjuntos anteriores\nprop = pd.merge(left=state,\n                right=very_liberal,\n                how='left',\n                on='state',\n                suffixes=('_total','_very_lib'))\n\n#Paso 4: Se crea obtiene la proporción de very libera de máxima verosimilitud por estado\nprop['prop_mle'] = prop['survey_very_lib'] / prop['survey_total']\n\n#Paso 5: Se eliminan estados que no son de interés\nprop = prop[~prop['state'].isin(['washington dc', 'hawaii', 'alaska'])]\nprop.head()\n\n\n\n\n\n\n\n\n\nstate\nsurvey_total\nideo\nsurvey_very_lib\nprop_mle\n\n\n\n\n0\nalabama\n624\nvery liberal\n30\n0.048077\n\n\n1\narizona\n542\nvery liberal\n28\n0.051661\n\n\n2\narkansas\n307\nvery liberal\n7\n0.022801\n\n\n3\ncalifornia\n2854\nvery liberal\n179\n0.062719\n\n\n4\ncolorado\n468\nvery liberal\n27\n0.057692\n\n\n\n\n\n\n\n\nAlgunas cosas que se pueden destacar de la tabla anterior, es que a pesar de que algunos estados pudieran presentar la misma proporción de very liberal, no necesariamente representa una cantidad significativa de votantes ya que esto depende de la población de cada estado. Tal es el caso de California comparado con Colorado, en donde porcentualmente tienen proporciones similares con \\(6.3\\%\\) y \\(5.8\\%\\) respectivamente, pero en el total de encuestas California es mucho mayor.\nPara tener idea del panorama de la proporción de very liberal comparado con el número de encuestas para cada uno de los estados, se puede realizar la siguiente visualización:\n\n\n\nCode\n#Scatter plot\nplt.figure(figsize=plot_settings['figsize'])\nplt.scatter(x=prop['survey_total'], y=prop['prop_mle'], s=100, color='red')\n\n#Anotaciones y estilo\nfor idx in prop.index:\n    x = prop.loc[idx]['survey_total']\n    y = prop.loc[idx]['prop_mle']\n    s = prop.loc[idx]['state'].upper().replace(' ', '')[0:4]\n    plt.text(x=x, y=y, s=s, fontsize=plot_settings['annotation'], rotation=60)\nplt.title(r'Proporción $very\\_liberal$ de máxima verosimilitud por estado', fontsize=plot_settings['title'])\nplt.xlabel('Número de encuestas realizadas', fontsize=plot_settings['text'])\nplt.ylabel('Proporción', fontsize=plot_settings['text'])\nplt.grid(alpha=0.2)\n\nplt.show()\n\n\n\n\n\n\nSe puede ver que la proporción de máxima verosimilitud de personas con ideología very liberal no incrementa linealmente con el tamaño de la población, de hecho, si se observa con detenimiento, se puede identificar que estados como California, Nueva York, o Texas, en donde se realizó un mayor número de encuestas, tienden a estar centrados en torno a una proporción del \\(5\\%\\). Lo anterior es contrastante con los estados en los que se realizaron menos de 500 encuestas, mismos que tienen mayor dispersión entre sí resultando en una gráfica que tiende a ser un cono que se abre a menor número de encuestas, pero que converge cuando estas aumentan.\nLo anterior puede dar una primera intuición de un enfoque frecuentista, y es que bajo esta lupa es razonable pensar que entre mayor sea el tamaño de la muestra, mayor convergencia se tendrá hacia el verdadero valor poblacional. En el caso de la proporción de personas very liberal se podría pensar que cada uno de los estados son una representación del comportamiento general de todo el país, por ende, si en el país la proporción de personas con dicha ideología es del \\(5\\%\\), entonces los diferentes estados tendrían que tener proporciones centradas en torno a este valor con una determinada varianza.\nSe puede hacer entonces una inspección visual del comportamiento de la proporción de personas very liberal contrastando el porcentaje de votos que recibió Obama. Para ello, primero es necesario recordar la idea inicial del ensayo, es decir, existe cierta correlación entre la proporción de votos que recibió Obama, con la proporción de votantes que se identifican liberales en cada estado. Para ello se puede realizar la siguiente gráfica:\n\n\n\nCode\n#Carga de datos de las elecciones\nresults = pd.read_csv('./data/2008ElectionResult.csv')\n\n#Paso 1: Descartar estados que no son de interés\nresults = results[~results['state'].isin(['District of Columbia', 'Hawaii', 'Alaska'])]\n\n#Paso 2: Formatear el nombre de los estados para compatibilidad\nresults['state'] = results['state'].str.lower()\n\n#Paso 3: Se incorpora la información al conjunto de datos\nprop = pd.merge(left=prop,\n                right=results[['state', 'vote_Obama_pct']],\n                how='left',\n                on='state')\n\n#Graficando votos por Obama contra proporción very liberal\nplt.figure(figsize=plot_settings['figsize'])\nplt.scatter(x=prop['vote_Obama_pct']/100, y=prop['prop_mle'], color='red', s=100)\n\n#Anotaciones y estilo\nfor idx in prop.index:\n    x = prop.loc[idx]['vote_Obama_pct']/100\n    y = prop.loc[idx]['prop_mle']\n    s = prop.loc[idx]['state'].upper().replace(' ', '')[0:4]\n    plt.text(x=x, y=y, s=s, fontsize=plot_settings['annotation'], rotation=60)\nplt.title(r'Comparación de los votos por Obama contra la proporción $very\\_liberal$ MLE', fontsize=plot_settings['title'])\nplt.xlabel('Proporción de votos por Obama', fontsize=plot_settings['text'])\nplt.ylabel('Proporción de very liberal MLE', fontsize=plot_settings['text'])\nplt.grid(alpha=0.2)\n\nplt.show()\n\n\n\n\n\n\nAntes de hablar con detalle de los aspectos interesantes de la visualización anterior, primero hay que aclarar que si bajo este enfoque existiera correlación entre ambas características, entonces se esperaría tener una tendencia creciente hacia arriba a la derecha, es decir, a mayor porcentaje de votos por Obama mayor porcentaje de personas very liberal. Esto, como lo hace evidente la gráfica, no sucede.\nDicho lo anterior, se pueden identificar claramente dos regiones tomando como referencia un \\(50\\%\\) de votos por Obama. Aproximadamente, desde este valor en adelante existe tendencia creciente en los votos que recibió el candidato, sin embargo, en los estados por debajo de esta referencia, la tendencia es contraria.\nAdicionalmente, también existen estados que rompen por completo las aparentes tendencias en dichas regiones. Esto se hace especialmente evidente en estados como Idaho, que presenta la mayor proporción de very liberal pero que en el resultado de las elecciones tuvo menos del \\(37\\%\\) de votantes por Obama; o como New Hampshire, que presenta la menor proporción de very liberal de todas, pero que en la elección tuvo casi el \\(55\\%\\) de votantes a favor del candidato."
  },
  {
    "objectID": "index.html#enfoque-bayesiano",
    "href": "index.html#enfoque-bayesiano",
    "title": "Un Enfoque Bayesiano",
    "section": "Enfoque Bayesiano",
    "text": "Enfoque Bayesiano\n\nHabiendo hablado del enfoque frecuentista, es tiempo de centrarse en el mismo análisis pero desde un punto de vista bayesiano. Sin embargo, antes de adentrarse en el problema, primero es necesario partir de dos ideas fundamentales.\nLa primera idea es que un enfoque bayesiano se apalanca de dos fuentes de información. Una fuente es el conocimiento que se tiene acerca del problema. Un ejemplo del día a día es aquel en el que se tiene que decidir si llevar paraguas al salir de casa o no. ¿Cómo se toma una decisión al respecto? probablemente se podría voltear a ver al cielo y evaluar si está nublado o soleado, y con base en ello suponer si lloverá o no, sea cual sea el caso, se tiene que tomar una decisión basada en las suposiciones que se tienen del problema. A esta fuente de información se le conoce como inicial.\nOtra fuente es la información extraída de los datos que se tienen del problema. En el ejemplo de la lluvia, si se cuenta con datos meteorológicos que indican que se está en temporada de lluvias y a una hora determinada está indicado que lloverá, entonces lo más probable es que llueva. En este punto es en donde se conectan ambos enfoques, ya que esta fuente de información es la máxima verosimilitud vista en la sección anterior.\nLa segunda idea es que en el mundo bayesiano, el conocimiento final o posterior será un punto intermedio entre las dos fuentes de información anteriores, es decir, la inicial y la verosimilitud. Dependiendo de qué tanta relevancia tenga cada una de ellas, será el qué tanto el conocimiento posterior se cargará hacia una u otra.\nSabiendo lo anterior la pregunta natural sería entonces ¿cómo se controla la relevancia de la información?, y como en casi todos los problemas de analítica, la respuesta depende del contexto del problema:\n\nSi se tiene mucha confianza en la información inicial (por ejemplo una distribución normal con alta curtosis y poca varianza), entonces se trata de un problema con una inicial muy relevante, por ende, la verosimilitud necesitará una gran cantidad de datos para poder moverla.\nSi por el contrario se tiene poca confianza en la información inicial (por ejemplo una distribución uniforme), entonces se trata de un problema con poca relevancia en la inicial, por ende, no tomarán demasiados datos para que la verosimilitud la desplace.\n\nPara ilustrarlo se retoma entonces el problema de Obama, en particular, utilizando la familia conjugada binomial-beta. Esta familia tiene la gentileza de que, para un conocimiento inicial distribuido beta de un fenómeno que se distribuye binomial, el conocimiento posterior también es distribuido beta pero con parámetros ajustados (Las ecuaciones de estos nuevos parámetros se muestran en el Anexo 2). Cabe aclarar que, para esta primera comparación, utilizar una familia conjugada es con propósitos estrictamente ilustrativos, formalmente debería utilizarse un modelo jerárquico. Dicho eso, se puede visualizar la distribución de personas con ideología very liberal obtenidas con un enfoque frecuentista.\n\n\n\nCode\nm = prop['prop_mle'].mean()\ns2 = prop['prop_mle'].var()\n\nfig, ax = plt.subplots(figsize=(3,3))\n\nplt.hist(x=prop['prop_mle'], color='grey', alpha=0.6)\nplt.title(f\"Distribución $very\\_liberal$ por estado\\n( $\\mu$: {m:.4f}, $\\sigma$: {np.sqrt(s2):.4f} )\", fontsize=plot_settings['title'])\nplt.grid(alpha=0.2)\n\nplt.show()\n\n\n\n\n\n\nEn este caso, lo que se observa es que la distribución de personas de cada estado que se identifican very liberal bajo un enfoque frecuentista, tiene una media de \\(\\mu\\approx 0.045\\) y desviación estándar \\(\\sigma\\approx 0.018\\). Se podría retomar la intuición de la sección anterior, es decir, cada uno de los estados es una representación del comportamiento general de todo el país, en donde el comportamiento general estaría centrado en \\(\\mu= 0.0459\\).\nLa idea en la que cada estado varía en mayor o menor medida de un valor central representa entonces el conocimiento inicial, queda definir su relevancia. En este caso, la relevancia queda dada por la desviación estándar de los datos, entre menor sea la desviación mayor será la influencia de la inicial sobre la posterior y viceversa. Se puede observar el efecto de la relevancia de la inicial comparando diferentes valores de \\(\\sigma\\), para ello, arbitrariamente se puede escoger un estado (por ejemplo Idaho), y se va a utilizar como referencia la desviación de la gráfica anterior, es decir, \\(\\sigma=0.018\\).\n\n\n\nCode\n#Función para obtener parámetros de beta posterior\ndef get_beta_params(mu, var): \n    a = mu * (-mu**2 + mu - var) / var\n    b = (mu - 1) * (mu**2 - mu + var) / var\n    return [a, b]\n\n#Parámetros de simulación\nsims = 1_000\nvar_list = [0.007**2, s2, 0.03**2]\nk = len(var_list)\n\n#Parámetros de estado\nstate = prop.loc[9]['state']\nn = prop.loc[9]['survey_total']\nx = prop.loc[9]['survey_very_lib']\n\n#Parámetros de figura\nfig = plt.figure(figsize=(9,4))\nspec = plt.GridSpec(ncols=k, nrows=1, hspace=0.3)\nticks = np.arange(0, 0.18, 0.05)\n\nfor idx in range(k):\n    #Parámetros de beta\n    a, b = get_beta_params(m, var_list[idx])\n    \n    #Distribución inicial\n    inicial = beta.rvs(a=a, b=b, size=sims, random_state=202803)\n    inicial_mean = inicial.mean()\n    \n    #Distribución posterior\n    posterior = beta.rvs(a=(a+x), b=(b+n-x), size=sims, random_state=202803)\n    \n    #Gráficas\n    ax_n = f\"ax{idx}\"\n    ax_n = fig.add_subplot(spec[idx])\n    ax_n.hist(x=inicial, bins=25, color='red', alpha=0.25, label='inicial')\n    ax_n.hist(x=posterior, bins=25, color='blue', alpha=0.25, label='posterior')\n    ax_n.axvline(x=inicial.mean(), color='red', label='mean_inicial')\n    ax_n.axvline(x=posterior.mean(), color='blue', label='mean_post')\n    ax_n.axvline(x=prop.loc[9]['prop_mle'], color='green', label='mle')\n    \n    #Anotaciones y estilo\n    ax_n.set_title(f\"$\\sigma$ = {np.sqrt(var_list[idx]):.3f}\", fontsize=plot_settings['text'])\n    ax_n.set_xlim(right=ticks.max())\n    ax_n.set_xticks(ticks)\n    ax_n.grid(alpha=0.2)\n\n#Anotaciones generales\nplt.suptitle(f\"Comparación del efecto de $\\sigma$ en la posterior, {state.title()}\", fontsize=plot_settings['title'])\nplt.legend()\nplt.show()\n\n\n\n\n\n\nDe la visualización anterior es importante resaltar que, para todos los gráficos del panel, tanto la proporción de máxima verosimilitud (Línea verde) como la media de la inicial (Línea roja) toman los mismos valores. Sin embargo, se observa que efectivamente, la inicial tiene mayor peso sobre la posterior a menor desviación estándar. Esto se ve tanto en la posición como en la dispersión de la posterior:\n\nPara una desviación estándar \\(\\sigma=0.007\\), la media de la posterior se encuentra aproximadamente en \\(0.05\\), mucho más cercana al valor de la inicial.\nPara la desviación estándar de referencia \\(\\sigma=0.018\\), la media de la posterior es cercana a \\(0.075\\), aproximadamente a la mitad entre la inicial y la verosimilitud.\nPara una desviación estándar \\(\\sigma=0.03\\), la media de la posterior se encuentra aproximadamente en \\(0.08\\), mucho más cercana al valor de la verosimilitud.\n\nAhora bien, una vez entendida la lógica detrás del enfoque bayesiano aplicado en un único estado, es tiempo de regresar al valor de referencia \\(\\sigma=0.018\\) y visualizar el comportamiento de todos los estados. Para ello, primero se pueden describir 9 estados de interés.\n\n\n\nCode\n#Parámetros de beta\na, b = get_beta_params(m, s2)\n\n#Parámetros de simulación\nsims = 1_000\ninicial = beta.rvs(a=a, b=b, size=sims, random_state=202803)\ninicial_mean = inicial.mean()\n\n#Parámetros de panel\npanels = 3\nstates_idx = [34,45,39,26,0,3,40,9,32]\n\n#Parámetros de figura\nfig = plt.figure(figsize=(9,9))\nspec = plt.GridSpec(ncols=panels, nrows=panels)\nk = 0\nfor idx in states_idx:\n    state = prop.loc[idx]['state']\n    \n    #Cálculo de la posterior\n    n = prop.loc[idx]['survey_total']\n    x = prop.loc[idx]['survey_very_lib']\n    posterior = beta.rvs(a=(a+x), b=(b+n-x), size=sims, random_state=202803)\n    \n    #Gráficas\n    ax_n = f\"ax{k}\"\n    ax_n = fig.add_subplot(spec[k])\n    ax_n.hist(x=inicial, bins=25, color='red', alpha=0.25, label='inicial')\n    ax_n.hist(x=posterior, bins=25, color='blue', alpha=0.25, label='posterior')\n    ax_n.axvline(x=inicial.mean(), color='red', label='mean_inicial')\n    ax_n.axvline(x=posterior.mean(), color='blue', label='mean_post')\n    ax_n.axvline(x=prop.loc[idx]['prop_mle'], color='green', label='mle')\n    \n    #Anotaciones y estilo\n    ax_n.set_title(state.title(), fontsize=plot_settings['text'])\n    ax_n.grid(alpha=0.2)\n    \n    k += 1\n\n#Anotaciones generales.\nplt.suptitle(f\"Comparación de diversos estados bajo $\\sigma$ = {np.sqrt(s2):.3f}\", fontsize=plot_settings['title'])\nplt.legend()\nplt.show()\n\n\n\n\n\n\nLa relevancia del panel anterior radica en que se puede ver con claridad el efecto de la inicial, que parte de ser la misma para todos los estados. Al considerarlo de esta manera, se está modelando el comportamiento promedio del país sobre cada uno de los estados, sin embargo, al haber modelado la verosimilitud de cada estado de manera independiente, se puede ver que la posterior de cada uno tiene comportamientos distintos dependiendo de varios posibles factores. Tomando como referencia la media de la verosimilitud (Línea verde), entonces:\n\nSi la verosimilitud está por debajo de la inicial, entonces la posterior se mueve hacia la derecha, como es el caso de New Hampshire o West Virginia.\nPor el contrario, si la verismilitud es mayor a la inicial entonces la posterior se recorre hacia la izquierda, como es el caso de Oregon o Idaho.\nSi se trata de un estado con poca represantación en las encuestas, entonces la inicial desplaza considerablemente a la posterior dejándola aproximadamente a la mitad, como es el caso de Idaho o New Hampshire.\nEn contraste, si se trata de un estado con mucha representación en las encuestas, entonces la inicial no tiene gran efecto sobre la posterior dejándola muy parecida a la verosimilitud, como es el caso de California o Texas.\nFinalmente, cuando tanto la inicial como la verosimilitud son muy parecidas, entonces la posterior también lo es independientemente de su representación en las encuestas, como es el caso de Ohio, Alabama, o Tennessee.\n\nAsí pues, nuevamente se visualiza la proporción de votos que tuvo Obama contra la proporción de very liberal por estado, en esta ocasión utilizando ambos enfoques.\n\n\n\nCode\n#Se crea columna vacía en dataframe\nprop['prop_bayes'] = np.nan\n\nfor idx in prop.index:\n    #Cálculo de la posterior\n    n = prop.loc[idx]['survey_total']\n    x = prop.loc[idx]['survey_very_lib']\n    posterior_mean = beta.rvs(a=(a+x), b=(b+n-x), size=sims, random_state=202803).mean()\n    \n    prop.loc[prop.index == idx, 'prop_bayes'] = posterior_mean\n\n#Graficando desplazamientos\nplt.figure(figsize=plot_settings['figsize'])\nplt.scatter(x=prop['vote_Obama_pct']/100, y=prop['prop_mle'], color='red', s=100, label='frecuentista', alpha=0.25)\nplt.scatter(x=prop['vote_Obama_pct']/100, y=prop['prop_bayes'], color='blue', s=100, label='bayesiano')\nfor idx in prop.index:\n    x = prop.loc[idx]['vote_Obama_pct']/100\n    y_mle = prop.loc[idx]['prop_mle']\n    y_bayes = prop.loc[idx]['prop_bayes']\n    plt.plot([x,x], [y_mle, y_bayes], color='black', alpha=0.25)\n\n#Anotaciones y estilo\nplt.title(r'Comparación de votos por Obama y proporción $very\\_liberal$ en ambos enfoques', fontsize=plot_settings['title'])\nplt.xlabel('Proporción de votos por Obama', fontsize=plot_settings['text'])\nplt.ylabel('Proporción de very liberal', fontsize=plot_settings['text'])\nplt.legend(fontsize=plot_settings['annotation'], loc=4)\nplt.grid(alpha=0.2)\n\nplt.show()\n\n\n\n\n\n\nLo primero que se puede notar, es que bajo el enfoque bayesiano se reduce la dispersión de los puntos, manifestando un comportamiento relativamente más centrado en torno a un valor de referencia en \\(\\mu=0.045\\), esto tiene sentido debido a que este enfoque partió de considerar la misma proporción de very liberal en todos los estados. Adicionalmente, de nueva cuenta se vuelve evidente que los estados que más desplazamiento sufrieron, fueron aquellos que tenían poca representación en las encuestas, o que originalmente se encontraban más alejados del valor de la inicial. Los estados que estaban por encima de \\(\\mu\\) bajaron, y los que se encontraban por debajo subieron."
  },
  {
    "objectID": "index.html#finalmente",
    "href": "index.html#finalmente",
    "title": "Un Enfoque Bayesiano",
    "section": "Finalmente",
    "text": "Finalmente\n\nCon este sencillo ejemplo es posible darse cuenta de las diferencias que hay entre ambos enfoques. Al mismo tiempo, también se puede indentificar el enorme potencial que tiene un enfoque bayesiano ya que, en principio, incorpora mayor cantidad de información al respecto de un tema, no nada más los datos. Sin embargo, esta propiedad que en principio puediera ser una virtud, también es el punto débil del mundo bayesiano, debido a que si la información inicial es incorrecta o está sesgada hacia alguna opinión parcial, se puede caer en errores sumamente graves o tendenciosos. Es precisamente en este punto en el que está la mayor crítica a los enfoques bayesianos."
  },
  {
    "objectID": "index.html#máxima-verosimilitud-de-una-binomial",
    "href": "index.html#máxima-verosimilitud-de-una-binomial",
    "title": "Un Enfoque Bayesiano",
    "section": "Máxima verosimilitud de una binomial",
    "text": "Máxima verosimilitud de una binomial\n\nMáxima verosimilitud de una distribución binomial (\\(n=1\\)):\nSean \\(X = \\{x_1,x_2,...,x_n\\}\\) muestras de una variable aleatoria independiente e idénticamente distribuida que siguen una distribución \\(x_i \\backsim B(k=1, p=\\theta)\\) siendo \\(k\\) el número de repeticiones del experimento, entonces:\nProbabilidad:\n\\[P(x_i|\\theta)=\\binom{1}{x_i}\\theta^{x_i}(1-\\theta)^{1-x_i}=\\theta^{x_i}(1-\\theta)^{1-x_i}\\]\nVerosimilitud:\n\\[L(\\theta|X)=\\prod_{i=1}^n P(x_i|\\theta)=\\prod_{i=1}^n\\left[\\theta^{x_i}(1-\\theta)^{1-x_i}\\right]\\]\nLog-verosimilitud:\n\\[ln[L(\\theta|X)]=\\sum_{i=1}^nln\\left[\\theta^{x_i}(1-\\theta)^{1-x_i}\\right]=ln\\theta\\sum x_i+ln(1-\\theta)\\sum(1-x_i)\\]\nDerivando e igualando a cero:\n\\[\\frac{\\partial}{\\partial\\theta}ln[L(\\theta|X)]=\\frac{1}{\\theta}\\sum x_i-\\frac{1}{1-\\theta}\\sum(1-x_i)=0\\]\n\\[(1-\\theta)\\sum x_i-\\theta\\sum(1-x_i)=0\\]\n\\[\\sum x_i - \\theta n  = 0\\]\n\\[\\therefore\\theta=\\frac{1}{n}\\sum_{i=1}^n x_i=\\bar x\\]\nEs decir:\n\\[\\theta=\\bar x\\]"
  },
  {
    "objectID": "index.html#parámetros-de-una-beta-binomial",
    "href": "index.html#parámetros-de-una-beta-binomial",
    "title": "Un Enfoque Bayesiano",
    "section": "Parámetros de una beta-binomial",
    "text": "Parámetros de una beta-binomial\n\nUtilizando el módulo de python sympy para cálculo simbólico, se obtuvieron las ecuaciones que resulven los parámetros \\(a\\), \\(b\\) de una distribución conjugada beta-binomial dados los valores de \\(\\mu\\), \\(\\sigma\\).\n\n\n\nCode\nfrom sympy import symbols, Eq, solve\nfrom sympy.abc import mu, sigma\n\na, b, s2, m = symbols(\"a b sigma^2 mu\")\n\nequation_1 = Eq( a / (a+b), m )\nequation_2 = Eq( a*b / ((a+b)**2 * (a + b + 1)), s2 )\nsolution = solve((equation_1, equation_2), (a, b))\n\nequation_1\n\n\n\\(\\displaystyle \\frac{a}{a + b} = \\mu\\)\n\n\n\n\nCode\nequation_2\n\n\n\\(\\displaystyle \\frac{a b}{\\left(a + b\\right)^{2} \\left(a + b + 1\\right)} = \\sigma^{2}\\)\n\n\n\n\nCode\nprint(\"Solución para el parámetro 'a':\\n\")\nsolution[0][0]\n\n\nSolución para el parámetro 'a':\n\n\n\n\\(\\displaystyle \\frac{\\mu \\left(- \\mu^{2} + \\mu - \\sigma^{2}\\right)}{\\sigma^{2}}\\)\n\n\n\n\nCode\nprint(\"Solución para el parámetro 'b':\\n\")\nsolution[0][1]\n\n\nSolución para el parámetro 'b':\n\n\n\n\\(\\displaystyle \\frac{\\left(\\mu - 1\\right) \\left(\\mu^{2} - \\mu + \\sigma^{2}\\right)}{\\sigma^{2}}\\)\n\n\nLas expresiones anteriores se pueden programar directamente en una función de python"
  },
  {
    "objectID": "chapters/english.html",
    "href": "chapters/english.html",
    "title": "A Bayesian Approach",
    "section": "",
    "text": "Annexes"
  },
  {
    "objectID": "chapters/english.html#introduction",
    "href": "chapters/english.html#introduction",
    "title": "A Bayesian Approach",
    "section": "Introduction",
    "text": "Introduction\n\nWhen I started my journey as a data scientist, I had little knowledge of programming languages, machine learning models, exploratory data analysis, etc. Initially, I imagined that data analytics was more about systems, computational power, and algorithms, but I never imagined it had anything to do with statistics. To me, statistics was just another subject that had to be fulfilled in my degree, and I saw it as something archaic and even tedious. Little did I know that years later it would become one of my favorite topics, that I would find fascinating the immense world it encompasses, and that I would realize its vast range of applications.\nIn this brief essay, I aim to demonstrate, with an applied example, the differences between a frequentist approach and a Bayesian approach. It is worth noting that this is the opinion of someone who is starting to delve into the world of Bayesian statistics, who believes that the best way to assimilate knowledge is by sharing it, and who is therefore making an effort to convey their initial impressions and intuitions on the subject.\nThe example I will use to illustrate the concepts is based on survey data from the 2008 United States presidential election, which can be found on the Pew Research Center website. This example was extracted from the book Bayesian Data Analysis by Andrew Gelman, 3rd edition - p. 61, and it is an expansion of work done for the course Fundamentals of Statistics taught in the Master’s in Data Science program at ITAM, by someone who quickly became one of the best professors I have had in my professional career, Teresa Ortiz."
  },
  {
    "objectID": "chapters/english.html#the-problem",
    "href": "chapters/english.html#the-problem",
    "title": "A Bayesian Approach",
    "section": "The Problem",
    "text": "The Problem\n\nAs it is well known, the 2008 United States election was won by the presidential candidate from the Democratic Party, Barack Obama. One might think that there is a certain correlation between the proportion of votes Obama received and the proportion of voters who identify as liberals in each state. To illustrate both approaches, a comparison will be made between the proportion of the population in each state that holds a “very liberal” political ideology (hereinafter referred to as “very liberal”), and the percentage of votes the candidate received in each state.\nTo make this comparison, we have two datasets. The first dataset consists of surveys conducted among the country’s citizens, where each record represents a surveyed person. The following variables are of interest:\n\nstate: The state where the survey was conducted.\nsurvey: An identifier for the survey applied to each record.\nideo: The political ideology of the survey respondent.\n\nThe second dataset contains the election results by state, with the focus on the following variables:\n\nstate: The reference state.\nvote_Obama_pct: The percentage of votes for Obama."
  },
  {
    "objectID": "chapters/english.html#frequentist-approach",
    "href": "chapters/english.html#frequentist-approach",
    "title": "A Bayesian Approach",
    "section": "Frequentist Approach",
    "text": "Frequentist Approach\n\nFor the first part of the analysis, we will obtain the proportion of the population that identifies as “very liberal” using a frequentist approach. In other words, we can obtain the maximum likelihood proportion using a binomial distribution. To do this, we can view each of the \\(n\\) respondents from a particular state \\(X = \\{x_1, x_2, ..., x_n\\}\\) as \\(n\\) samples from an independent and identically distributed random variable, following a distribution \\(x_i \\sim B(k=1, p=\\theta)\\), where a person with such an ideology is considered a success in a binomial setting.\nThe maximum likelihood estimator for a binomial distribution with \\(k=1\\) is given by:\n\\[\\theta = \\bar x\\]\nIn the case of the example, we can obtain this estimator of proportion (prop_mle) by using the total number of surveys conducted in a state (survey_total) and the total number of respondents who identified as “very liberal” (survey_very_lib) in their political ideology. This is further illustrated in the following table, which only shows the first five states for simplicity.\n\n\n\n\n\n\nNote\n\n\n\nThe demonstration of the estimator \\(\\theta\\) can be found in Annex 1.\n\n\n\n\n\nCode\n#Carga de datos de encuestas\npoll_data = pd.read_stata('../data/pew_research_center_june_elect_wknd_data.dta')\n\n#Paso 1: Se agrupa por estado para obtener el número de encuestas realizadas en cada estada\nstate = poll_data.groupby(by='state').count()\nstate.reset_index(inplace=True)\nstate = state[['state', 'survey']]\n\n#Paso 2: Se agrupa por estado e ideología para filtrar encuestas very liberal\nideo = poll_data.groupby(by=['state','ideo']).count()\nideo.reset_index(inplace=True)\nideo = ideo[['state', 'ideo', 'survey']]\nvery_liberal = ideo.loc[ideo['ideo'] == 'very liberal']\n\n#Paso 3: Se unen los dos conjuntos anteriores\nprop = pd.merge(left=state,\n                right=very_liberal,\n                how='left',\n                on='state',\n                suffixes=('_total','_very_lib'))\n\n#Paso 4: Se crea obtiene la proporción de very libera de máxima verosimilitud por estado\nprop['prop_mle'] = prop['survey_very_lib'] / prop['survey_total']\n\n#Paso 5: Se eliminan estados que no son de interés\nprop = prop[~prop['state'].isin(['washington dc', 'hawaii', 'alaska'])]\nprop.head()\n\n\n\n\n\n\n\n\n\nstate\nsurvey_total\nideo\nsurvey_very_lib\nprop_mle\n\n\n\n\n0\nalabama\n624\nvery liberal\n30\n0.048077\n\n\n1\narizona\n542\nvery liberal\n28\n0.051661\n\n\n2\narkansas\n307\nvery liberal\n7\n0.022801\n\n\n3\ncalifornia\n2854\nvery liberal\n179\n0.062719\n\n\n4\ncolorado\n468\nvery liberal\n27\n0.057692\n\n\n\n\n\n\n\n\nSome key points to highlight from the above table are that, although some states may have the same proportion of “very liberal” individuals, it does not necessarily represent a significant number of voters as this depends on the population of each state. This is the case with California compared to Colorado, where they have similar proportions at \\(6.3\\%\\) and \\(5.8\\%\\) respectively, but California has a much larger number of surveys conducted overall.\nTo get an idea of the distribution of the “very liberal” proportion compared to the number of surveys for each state, the following visualization can be created:\n\n\n\nCode\n#Scatter plot\nplt.figure(figsize=plot_settings['figsize'])\nplt.scatter(x=prop['survey_total'], y=prop['prop_mle'], s=100, color='red')\n\n#Anotaciones y estilo\nfor idx in prop.index:\n    x = prop.loc[idx]['survey_total']\n    y = prop.loc[idx]['prop_mle']\n    s = prop.loc[idx]['state'].upper().replace(' ', '')[0:4]\n    plt.text(x=x, y=y, s=s, fontsize=plot_settings['annotation'], rotation=60)\nplt.title(r'$very\\_liberal$ maximum likelihood proportion by state', fontsize=plot_settings['title'])\nplt.xlabel('Number of surveys conducted', fontsize=plot_settings['text'])\nplt.ylabel('Proportion', fontsize=plot_settings['text'])\nplt.grid(alpha=0.2)\n\nplt.show()\n\n\n\n\n\n\nIt can be observed that the maximum likelihood proportion of individuals with a “very liberal” ideology does not increase linearly with the population size. In fact, upon careful observation, it can be identified that states like California, New York, or Texas, where a larger number of surveys were conducted, tend to be centered around a proportion of \\(5\\%\\). This is in contrast to states where fewer than 500 surveys were conducted, which exhibit greater dispersion among themselves, resulting in a graph that tends to resemble a cone opening up as the number of surveys decreases but converging as the number of surveys increases.\nThis provides an initial intuition from a frequentist perspective, suggesting that with larger sample sizes, there is greater convergence towards the true population value. In the case of the proportion of “very liberal” individuals, one could think of each state as a representation of the overall behavior of the entire country. Therefore, if the proportion of individuals with this ideology in the country is \\(5\\%\\), then different states should have proportions centered around this value with a certain variance.\nNow, a visual inspection can be performed to explore the behavior of the proportion of “very liberal” individuals in contrast to the percentage of votes received by Obama. To do this, it is necessary to revisit the initial idea of the essay, which suggests a correlation between the proportion of votes received by Obama and the proportion of voters who identify as liberals in each state. The following graph can be created for this purpose:\n\n\n\nCode\n#Carga de datos de las elecciones\nresults = pd.read_csv('../data/2008ElectionResult.csv')\n\n#Paso 1: Descartar estados que no son de interés\nresults = results[~results['state'].isin(['District of Columbia', 'Hawaii', 'Alaska'])]\n\n#Paso 2: Formatear el nombre de los estados para compatibilidad\nresults['state'] = results['state'].str.lower()\n\n#Paso 3: Se incorpora la información al conjunto de datos\nprop = pd.merge(left=prop,\n                right=results[['state', 'vote_Obama_pct']],\n                how='left',\n                on='state')\n\n#Graficando votos por Obama contra proporción very liberal\nplt.figure(figsize=plot_settings['figsize'])\nplt.scatter(x=prop['vote_Obama_pct']/100, y=prop['prop_mle'], color='red', s=100)\n\n#Anotaciones y estilo\nfor idx in prop.index:\n    x = prop.loc[idx]['vote_Obama_pct']/100\n    y = prop.loc[idx]['prop_mle']\n    s = prop.loc[idx]['state'].upper().replace(' ', '')[0:4]\n    plt.text(x=x, y=y, s=s, fontsize=plot_settings['annotation'], rotation=60)\nplt.title(r'Obama votes vs $very\\_liberal$ MLE proportion comparison', fontsize=plot_settings['title'])\nplt.xlabel('Obama votes proportion', fontsize=plot_settings['text'])\nplt.ylabel('very liberal MLE proportion', fontsize=plot_settings['text'])\nplt.grid(alpha=0.2)\n\nplt.show()\n\n\n\n\n\n\nBefore discussing the interesting aspects of the previous visualization in detail, it is important to clarify that if there were a correlation between these two variables under this approach, one would expect to see an upward trend towards the top right, indicating that a higher percentage of votes for Obama corresponds to a higher percentage of “very liberal” individuals. However, as evident from the graph, this is not the case.\nWith that being said, two distinct regions can be clearly identified when using a reference of \\(50\\%\\) of votes for Obama. Approximately, from this threshold onwards, there is an increasing trend in the votes received by the candidate. However, in states below this reference, the trend is the opposite.\nAdditionally, there are states that completely defy the apparent trends in these regions. This is particularly evident in states like Idaho, which has the highest proportion of “very liberal” individuals but received less than \\(37\\%\\) of votes for Obama in the election. On the other hand, states like New Hampshire have the lowest proportion of “very liberal” individuals, yet had almost \\(55\\%\\) of voters supporting the candidate."
  },
  {
    "objectID": "chapters/english.html#bayesian-approach",
    "href": "chapters/english.html#bayesian-approach",
    "title": "A Bayesian Approach",
    "section": "Bayesian Approach",
    "text": "Bayesian Approach\n\nHaving discussed the frequentist approach, it is now time to focus on the same analysis from a Bayesian point of view. However, before delving into the problem, it is necessary to start with two fundamental ideas.\nThe first idea is that a Bayesian approach leverages two sources of information. One source is the knowledge we have about the problem. An everyday example is when deciding whether to bring an umbrella when leaving the house or not. How do we make such a decision? We might look at the sky and evaluate whether it is cloudy or sunny, and based on that, make assumptions about whether it will rain or not. Regardless of the case, a decision has to be made based on the assumptions we have about the problem. This source of information is known as the prior.\nAnother source is the information extracted from the data we have about the problem. In the example of rain, if we have meteorological data indicating that we are in the rainy season and that it is forecasted to rain at a specific time, then it is most likely going to rain. At this point, the two approaches converge, as this source of information is the maximum likelihood seen in the previous section.\nThe second idea is that in the Bayesian world, the final or posterior knowledge will be an intermediate point between the two aforementioned sources of information, i.e., the prior and the likelihood. Depending on the relevance of each source, the posterior knowledge will lean more towards one or the other.\nKnowing this, the natural question then arises: how is the relevance of the information controlled? As with most analytics problems, the answer depends on the context of the problem:\n\nIf there is a high level of confidence in the prior information (e.g., a normal distribution with high kurtosis and low variance), it represents a problem with highly relevant prior knowledge. Consequently, the likelihood will require a large amount of data to be shifted.\nConversely, if there is little confidence in the prior information (e.g., a uniform distribution), it represents a problem with little relevance in the prior. Consequently, it will not take much data to shift the likelihood.\n\nTo illustrate this, let’s revisit the Obama problem, specifically using the conjugate binomial-beta family. This family has the property that, for an initial beta-distributed knowledge of a binomial-distributed phenomenon, the posterior knowledge is also beta-distributed but with adjusted parameters (the equations for these new parameters are shown in Appendix 2). It should be noted that, for this initial comparison, using a conjugate family is strictly for illustrative purposes. Formally, a hierarchical model should be used. With that said, we can visualize the distribution of individuals with a “very liberal” ideology obtained using a frequentist approach.\n\n\n\nCode\nm = prop['prop_mle'].mean()\ns2 = prop['prop_mle'].var()\n\nfig, ax = plt.subplots(figsize=(3,3))\n\nplt.hist(x=prop['prop_mle'], color='grey', alpha=0.6)\nplt.title(f\"$very\\_liberal$ distribution by state\\n( $\\mu$: {m:.4f}, $\\sigma$: {np.sqrt(s2):.4f} )\", fontsize=plot_settings['title'])\nplt.grid(alpha=0.2)\n\nplt.show()\n\n\n\n\n\n\nIn this case, what is observed is that the distribution of individuals in each state who identify as “very liberal” under a frequentist approach has a mean of \\(\\mu \\approx 0.045\\) and standard deviation of \\(\\sigma \\approx 0.018\\). We can revisit the intuition from the previous section, where each state is a representation of the general behavior of the entire country, with the overall behavior centered around \\(\\mu = 0.0459\\).\nThe idea that each state varies to a greater or lesser extent from a central value represents the prior knowledge. The relevance of the prior needs to be defined. In this case, relevance is determined by the standard deviation of the data. The smaller the standard deviation, the greater the influence of the prior on the posterior, and vice versa. The effect of the relevance of the prior can be observed by comparing different values of \\(\\sigma\\). For this purpose, we can arbitrarily choose a state (e.g., Idaho) and use the standard deviation from the previous graph as a reference, i.e., \\(\\sigma = 0.018\\).\n\n\n\nCode\n#Función para obtener parámetros de beta posterior\ndef get_beta_params(mu, var): \n    a = mu * (-mu**2 + mu - var) / var\n    b = (mu - 1) * (mu**2 - mu + var) / var\n    return [a, b]\n\n#Parámetros de simulación\nsims = 1_000\nvar_list = [0.007**2, s2, 0.03**2]\nk = len(var_list)\n\n#Parámetros de estado\nstate = prop.loc[9]['state']\nn = prop.loc[9]['survey_total']\nx = prop.loc[9]['survey_very_lib']\n\n#Parámetros de figura\nfig = plt.figure(figsize=(9,4))\nspec = plt.GridSpec(ncols=k, nrows=1, hspace=0.3)\nticks = np.arange(0, 0.18, 0.05)\n\nfor idx in range(k):\n    #Parámetros de beta\n    a, b = get_beta_params(m, var_list[idx])\n    \n    #Distribución inicial\n    inicial = beta.rvs(a=a, b=b, size=sims, random_state=202803)\n    inicial_mean = inicial.mean()\n    \n    #Distribución posterior\n    posterior = beta.rvs(a=(a+x), b=(b+n-x), size=sims, random_state=202803)\n    \n    #Gráficas\n    ax_n = f\"ax{idx}\"\n    ax_n = fig.add_subplot(spec[idx])\n    ax_n.hist(x=inicial, bins=25, color='red', alpha=0.25, label='initial')\n    ax_n.hist(x=posterior, bins=25, color='blue', alpha=0.25, label='posterior')\n    ax_n.axvline(x=inicial.mean(), color='red', label='mean_initial')\n    ax_n.axvline(x=posterior.mean(), color='blue', label='mean_post')\n    ax_n.axvline(x=prop.loc[9]['prop_mle'], color='green', label='mle')\n    \n    #Anotaciones y estilo\n    ax_n.set_title(f\"$\\sigma$ = {np.sqrt(var_list[idx]):.3f}\", fontsize=plot_settings['text'])\n    ax_n.set_xlim(right=ticks.max())\n    ax_n.set_xticks(ticks)\n    ax_n.grid(alpha=0.2)\n\n#Anotaciones generales\nplt.suptitle(f\"Comparing the effect of $\\sigma$ in the posterior, {state.title()}\", fontsize=plot_settings['title'])\nplt.legend()\nplt.show()\n\n\n\n\n\n\nFrom the previous visualization, it is important to highlight that, for all the graphs in the panel, both the maximum likelihood proportion (green line) and the mean of the prior (red line) take the same values. However, it is observed that the prior indeed has a greater influence on the posterior as the standard deviation decreases. This is evident in both the position and dispersion of the posterior:\n\nFor a standard deviation of \\(\\sigma=0.007\\), the mean of the posterior is approximately at \\(0.05\\), much closer to the value of the prior.\nFor the reference standard deviation of \\(\\sigma=0.018\\), the mean of the posterior is close to \\(0.075\\), approximately halfway between the prior and the likelihood.\nFor a standard deviation of \\(\\sigma=0.03\\), the mean of the posterior is approximately at \\(0.08\\), much closer to the value of the likelihood.\n\nNow that we understand the logic behind the Bayesian approach applied to a single state, let’s go back to the reference value of \\(\\sigma=0.018\\) and visualize the behavior of all the states. To do this, we can first describe 9 states of interest.\n\n\n\nCode\n#Parámetros de beta\na, b = get_beta_params(m, s2)\n\n#Parámetros de simulación\nsims = 1_000\ninicial = beta.rvs(a=a, b=b, size=sims, random_state=202803)\ninicial_mean = inicial.mean()\n\n#Parámetros de panel\npanels = 3\nstates_idx = [34,45,39,26,0,3,40,9,32]\n\n#Parámetros de figura\nfig = plt.figure(figsize=(9,9))\nspec = plt.GridSpec(ncols=panels, nrows=panels)\nk = 0\nfor idx in states_idx:\n    state = prop.loc[idx]['state']\n    \n    #Cálculo de la posterior\n    n = prop.loc[idx]['survey_total']\n    x = prop.loc[idx]['survey_very_lib']\n    posterior = beta.rvs(a=(a+x), b=(b+n-x), size=sims, random_state=202803)\n    \n    #Gráficas\n    ax_n = f\"ax{k}\"\n    ax_n = fig.add_subplot(spec[k])\n    ax_n.hist(x=inicial, bins=25, color='red', alpha=0.25, label='initial')\n    ax_n.hist(x=posterior, bins=25, color='blue', alpha=0.25, label='posterior')\n    ax_n.axvline(x=inicial.mean(), color='red', label='mean_initial')\n    ax_n.axvline(x=posterior.mean(), color='blue', label='mean_post')\n    ax_n.axvline(x=prop.loc[idx]['prop_mle'], color='green', label='mle')\n    \n    #Anotaciones y estilo\n    ax_n.set_title(state.title(), fontsize=plot_settings['text'])\n    ax_n.grid(alpha=0.2)\n    \n    k += 1\n\n#Anotaciones generales.\nplt.suptitle(f\"Comparing multiple states given $\\sigma$ = {np.sqrt(s2):.3f}\", fontsize=plot_settings['title'])\nplt.legend()\nplt.show()\n\n\n\n\n\n\nThe relevance of the previous panel lies in the clear visualization of the effect of the prior, which starts out the same for all states. By considering it in this way, we are modeling the average behavior of the country across each state. However, since we modeled the likelihood of each state independently, it can be seen that the posterior of each state exhibits different behaviors depending on various possible factors. Taking the mean of the likelihood as a reference (green line), we can observe the following:\n\nIf the likelihood is below the prior, then the posterior shifts to the right, as seen in the cases of New Hampshire or West Virginia.\nConversely, if the likelihood is higher than the prior, then the posterior shifts to the left, as seen in the cases of Oregon or Idaho.\nIf a state has low representation in the surveys, the prior significantly influences the posterior, placing it roughly in the middle, as observed in Idaho or New Hampshire.\nIn contrast, if a state has high representation in the surveys, the prior has little effect on the posterior, resulting in a posterior distribution that closely resembles the likelihood, as seen in California or Texas.\nFinally, when both the prior and the likelihood are very similar, the posterior distribution also becomes very similar, regardless of the state’s representation in the surveys. This is the case for Ohio, Alabama, or Tennessee.\n\nThus, once again, we visualize the proportion of votes that Obama received against the proportion of “very liberal” individuals by state, this time using both approaches.\n\n\n\nCode\n#Se crea columna vacía en dataframe\nprop['prop_bayes'] = np.nan\n\nfor idx in prop.index:\n    #Cálculo de la posterior\n    n = prop.loc[idx]['survey_total']\n    x = prop.loc[idx]['survey_very_lib']\n    posterior_mean = beta.rvs(a=(a+x), b=(b+n-x), size=sims, random_state=202803).mean()\n    \n    prop.loc[prop.index == idx, 'prop_bayes'] = posterior_mean\n\n#Graficando desplazamientos\nplt.figure(figsize=plot_settings['figsize'])\nplt.scatter(x=prop['vote_Obama_pct']/100, y=prop['prop_mle'], color='red', s=100, label='frequentist', alpha=0.25)\nplt.scatter(x=prop['vote_Obama_pct']/100, y=prop['prop_bayes'], color='blue', s=100, label='bayesian')\nfor idx in prop.index:\n    x = prop.loc[idx]['vote_Obama_pct']/100\n    y_mle = prop.loc[idx]['prop_mle']\n    y_bayes = prop.loc[idx]['prop_bayes']\n    plt.plot([x,x], [y_mle, y_bayes], color='black', alpha=0.25)\n\n#Anotaciones y estilo\nplt.title(r'Comparing Obama votes vs $very\\_liberal$ proportion in both approaches', fontsize=plot_settings['title'])\nplt.xlabel('Obama votes proportion', fontsize=plot_settings['text'])\nplt.ylabel('very liberal proportion', fontsize=plot_settings['text'])\nplt.legend(fontsize=plot_settings['annotation'], loc=4)\nplt.grid(alpha=0.2)\n\nplt.show()\n\n\n\n\n\n\nThe first thing to note is that under the Bayesian approach, the dispersion of the points is reduced, indicating a relatively more centered behavior around a reference value of \\(\\mu=0.045\\). This makes sense since this approach initially considered the same proportion of “very liberal” individuals in all states. Additionally, it becomes evident once again that the states that experienced the most displacement were those with low representation in the surveys or those that were originally further away from the value of the prior. States that were above \\(\\mu\\) moved downward, and those that were below moved upward."
  },
  {
    "objectID": "chapters/english.html#finally",
    "href": "chapters/english.html#finally",
    "title": "A Bayesian Approach",
    "section": "Finally",
    "text": "Finally\n\nWith this simple example, it is possible to appreciate the differences between the two approaches. At the same time, one can also identify the enormous potential of a Bayesian approach, as it incorporates more information about a topic, not just the data. However, this property that can initially be seen as a virtue is also the weak point of the Bayesian world. If the prior information is incorrect or biased towards a particular opinion, it can lead to serious and biased errors. This is precisely the main criticism of Bayesian approaches."
  },
  {
    "objectID": "chapters/english.html#maximum-likelihood-of-a-binomial-distribution",
    "href": "chapters/english.html#maximum-likelihood-of-a-binomial-distribution",
    "title": "A Bayesian Approach",
    "section": "Maximum likelihood of a binomial distribution",
    "text": "Maximum likelihood of a binomial distribution\n\nMaximum likelihood of a binomial distribution (\\(n=1\\)):\nLet \\(X = \\{x_1,x_2,...,x_n\\}\\) be samples from an independent and identically distributed random variable following a distribution \\(x_i \\sim B(k=1, p=\\theta)\\), where \\(k\\) is the number of repetitions of the experiment. Then:\nProbability:\n\\[P(x_i|\\theta)=\\binom{1}{x_i}\\theta^{x_i}(1-\\theta)^{1-x_i}=\\theta^{x_i}(1-\\theta)^{1-x_i}\\]\nLikelihood:\n\\[L(\\theta|X)=\\prod_{i=1}^n P(x_i|\\theta)=\\prod_{i=1}^n\\left[\\theta^{x_i}(1-\\theta)^{1-x_i}\\right]\\]\nLog-likelihood:\n\\[ln[L(\\theta|X)]=\\sum_{i=1}^nln\\left[\\theta^{x_i}(1-\\theta)^{1-x_i}\\right]=ln\\theta\\sum x_i+ln(1-\\theta)\\sum(1-x_i)\\]\nDerivative equal to cero:\n\\[\\frac{\\partial}{\\partial\\theta}ln[L(\\theta|X)]=\\frac{1}{\\theta}\\sum x_i-\\frac{1}{1-\\theta}\\sum(1-x_i)=0\\]\n\\[(1-\\theta)\\sum x_i-\\theta\\sum(1-x_i)=0\\]\n\\[\\sum x_i - \\theta n  = 0\\]\n\\[\\therefore\\theta=\\frac{1}{n}\\sum_{i=1}^n x_i=\\bar x\\]\nWhich means:\n\\[\\theta=\\bar x\\]"
  },
  {
    "objectID": "chapters/english.html#beta-binomial-parameters",
    "href": "chapters/english.html#beta-binomial-parameters",
    "title": "A Bayesian Approach",
    "section": "Beta-Binomial parameters",
    "text": "Beta-Binomial parameters\n\nUsing the sympy module in Python for symbolic computation, the equations that solve the parameters \\(a\\) and \\(b\\) of a conjugate beta-binomial distribution given the values of \\(\\mu\\) and \\(\\sigma\\) were obtained.\n\n\n\nCode\nfrom sympy import symbols, Eq, solve\nfrom sympy.abc import mu, sigma\n\na, b, s2, m = symbols(\"a b sigma^2 mu\")\n\nequation_1 = Eq( a / (a+b), m )\nequation_2 = Eq( a*b / ((a+b)**2 * (a + b + 1)), s2 )\nsolution = solve((equation_1, equation_2), (a, b))\n\nequation_1\n\n\n\\(\\displaystyle \\frac{a}{a + b} = \\mu\\)\n\n\n\n\nCode\nequation_2\n\n\n\\(\\displaystyle \\frac{a b}{\\left(a + b\\right)^{2} \\left(a + b + 1\\right)} = \\sigma^{2}\\)\n\n\n\n\nCode\nprint(\"Solution for 'a' parameter:\\n\")\nsolution[0][0]\n\n\nSolution for 'a' parameter:\n\n\n\n\\(\\displaystyle \\frac{\\mu \\left(- \\mu^{2} + \\mu - \\sigma^{2}\\right)}{\\sigma^{2}}\\)\n\n\n\n\nCode\nprint(\"Solution for 'b' parameter:\\n\")\nsolution[0][1]\n\n\nSolution for 'b' parameter:\n\n\n\n\\(\\displaystyle \\frac{\\left(\\mu - 1\\right) \\left(\\mu^{2} - \\mu + \\sigma^{2}\\right)}{\\sigma^{2}}\\)\n\n\nPrevious expresions can be porgrammed directily in a python function."
  }
]